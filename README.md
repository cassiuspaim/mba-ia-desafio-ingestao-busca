# RAG â€“ IngestÃ£o, Busca Vetorial e Chat com OpenAI/Gemini

Este projeto implementa um pipeline completo para:

- IngestÃ£o de documentos PDF  
- GeraÃ§Ã£o de embeddings (OpenAI ou Gemini)  
- Armazenamento vetorial com PostgreSQL + pgVector  
- Chat via linha de comando utilizando RAG (Retrieval Augmented Generation)

O sistema responde **apenas com base no PDF ingerido**, sem conhecimento externo.

---

# ğŸ§© 1. Configurar `.env`

Crie um arquivo `.env` na raiz do projeto.  
Use o `.env.example` como referÃªncia.

Preencha:

```
OPENAI_API_KEY=sua_chave
GEMINI_API_KEY=sua_chave
AI_PROVIDER=openai  # ou gemini
```

---

# ğŸ˜ 2. Subir o banco PostgreSQL + pgVector

```
docker compose up -d
```

---

# ğŸ“¥ 3. Rodar a ingestÃ£o do PDF

```
python src/ingest.py
```

---

# ğŸ’¬ 4. Rodar o chat

```
python src/chat.py
```

---

# ğŸ”„ 5. Resetar o banco (obrigatÃ³rio ao trocar provedor)

Se vocÃª mudar `AI_PROVIDER`, precisa recriar o banco:

```
docker compose down -v
docker compose up -d
python src/ingest.py
```

---

# ğŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ document.pdf
â””â”€â”€ src/
    â”œâ”€â”€ ingest.py
    â”œâ”€â”€ search.py
    â””â”€â”€ chat.py
```

---

# ğŸ›  Comandos Ãºteis

| AÃ§Ã£o | Comando |
|------|---------|
| Parar containers | docker compose down |
| Parar + apagar volume | docker compose down -v |
| Ver logs | docker compose logs -f postgres |
| Acessar banco | docker exec -it postgres_rag psql -U postgres -d rag |

---

# ğŸ§ª Fluxo completo

```
cp .env.example .env
nano .env
docker compose up -d
python src/ingest.py
python src/chat.py
```

---

# ğŸ“Œ ObservaÃ§Ãµes

- O chat sÃ³ responde com base no PDF.
- Sempre resete o banco ao trocar o provedor de IA.
